services:
  kafka:
    image: apache/kafka:latest
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      - KAFKA_NODE_ID=0
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      - KAFKA_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=false
    volumes:
      - kafka_data:/var/lib/kafka/data

  kafka-init:
    image: apache/kafka:latest
    depends_on:
      - kafka
    entrypoint: ["/bin/bash","-c"]
    command: >
      "/opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists
      --topic transactions --partitions 3 --replication-factor 1 &&
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists
      --topic fraud_alerts --partitions 3 --replication-factor 1 &&
      echo 'Kafka topics ready.'"

  jupyter:
    image: jupyter/pyspark-notebook:latest
    container_name: jupyter
    ports:
      - "8888:8888"
    environment:
      - JUPYTER_ENABLE_LAB=yes
    volumes:
      - ./work:/home/jovyan/work
    depends_on:
      - kafka

  producer:
    build: ./producer
    depends_on:
      - kafka-init
    environment:
      - KAFKA_BOOTSTRAP=kafka:9092
      - TOPIC=transactions
      - CSV_PATH=/work/data/creditcard.csv
      - STREAM_MODE=steady
      - BATCH_SIZE=500
      - SLEEP_MS=250
    volumes:
      - ./work:/work
      - ./scripts:/work/scripts
    command: ["python","producer_enhanced.py"]

  spark-streaming:
    build: ./spark-streaming
    container_name: spark-streaming
    depends_on:
      - kafka-init
    environment:
      - KAFKA_BOOTSTRAP=kafka:9092
      - INPUT_TOPIC=transactions
      - OUTPUT_TOPIC=fraud_alerts
      - MODEL_PATH=/work/models/fraud_lr_model
      - FRAUD_THRESHOLD=0.0186
      - CHECKPOINT_DIR=/work/checkpoints
      - CSV_PATH=/work/data/creditcard.csv
    volumes:
      - ./work:/work
      - ./data:/work/data
    restart: unless-stopped
    command: ["spark-submit", "--packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0", "--master", "local[*]", "--driver-memory", "2g", "/home/jovyan/fraud_detection_working.py"]

volumes:
  kafka_data:
